{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8W2fg1cyGdX",
    "outputId": "22ead814-bb75-4268-eb6c-3cfe869428a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 135,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "gONY1YiDq7jD"
   },
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DR_YMBsyOci",
    "outputId": "6953b35c-47fa-4080-da11-5527a724ae54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HpvTwDHyQQy",
    "outputId": "67e7a9ad-f1b2-4fa1-d7ad-e1bc22440fa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYaVyQ2lyXcr",
    "outputId": "4a76d506-d587-45e5-98eb-abd237b7ec81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.08 seconds.\n",
      "Convergence after 10 epochs took 0.08 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EAfkVI6GyaRO",
    "outputId": "80ea764e-af95-4da5-8c96-3d5151045d3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "  w=np.zeros(len(dim))\n",
    "  b=0\n",
    "  return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pv1llH429wG5",
    "outputId": "bbb12a0f-f3aa-4017-bb55-b7bce8d18199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "  return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def sigmoid(z):\n",
    "  sig = 1/(1 + math.exp(-z))\n",
    "  \n",
    "  return sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_JASp_NAfK_",
    "outputId": "54ef5ed1-395a-4776-a0af-0a7a6be5550e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "  val=sigmoid(z)\n",
    "  assert(val==0.8807970779778823)\n",
    "  return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "  n = len(y_true)\n",
    "  loss = 0\n",
    "  for i in range(n):\n",
    "    loss +=  (y_true[i] *math.log(y_pred[i],10)) + (1-y_true[i])*math.log((1-y_pred[i]),10)\n",
    "  log_loss = -loss/n  \n",
    "    #'''In this function, we will compute log loss '''\n",
    "\n",
    "  return log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "LzttjvBFCuQ5",
    "outputId": "d1e0b04d-4190-4a9f-f2f4-2de524c57e80"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-0d97b9a00c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgrader_logloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-171-0d97b9a00c90>\u001b[0m in \u001b[0;36mgrader_logloss\u001b[0;34m(true, pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrader_logloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0.07644900402910389\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "  loss=logloss(true,pred)\n",
    "  assert(loss==0.07644900402910389)\n",
    "  return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9pP0iIS5_md",
    "outputId": "b4b52687-f2aa-4372-ea42-66518aeb3288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07644900402910386\n"
     ]
    }
   ],
   "source": [
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "a = logloss(true,pred)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "I9H1T7_6Mykk"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "  y1 = np.dot(w.T,x) + b\n",
    "  sig = sigmoid(y1)\n",
    "  dw = x*(y - sig) -(alpha/N)*w.T\n",
    "\n",
    "  return dw  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI3xD8ctGEnJ",
    "outputId": "ee95ecf6-b602-40d2-ecd2-a04ea20c08df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "  assert(np.sum(grad_dw)==2.613689585)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    " def gradient_db(x,y,w,b):\n",
    "   y1 = np.dot(w.T,x) + b\n",
    "   sig = sigmoid(y1)\n",
    "\n",
    "   db = y - sig\n",
    "     #'''In this function, we will compute gradient w.r.to b '''\n",
    "   return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfFDKmscG5qZ",
    "outputId": "1f80b925-7431-4d47-c35a-371a2f3dbe1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "  grad_db=gradient_db(x,y,w,b)\n",
    "  assert(grad_db==-0.5)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "  train_loss , test_loss = list(), list()\n",
    "  w,b = initialize_weights(X_train[0])\n",
    "  N = len(X_train)\n",
    "  for i in range(epochs):\n",
    "    for i in range(len(X_train)):\n",
    "      dw = gradient_dw(X_train[i],y_train[i],w,b,alpha,N)\n",
    "      db = gradient_db(X_train[i],y_train[i],w,b)\n",
    "      w = w + eta0*dw\n",
    "      b = b + eta0*db\n",
    "   \n",
    "    y_train_pred = []\n",
    "    for i in range(len(X_train)):\n",
    "      z = np.dot(w.T,X_train[i]) + b\n",
    "      sig = sigmoid(z)\n",
    "      y_train_pred.append(sig)\n",
    "    train_loss.append(logloss(y_train,y_train_pred))\n",
    "\n",
    "    y_test_pred = []\n",
    "    for i in range(len(X_test)):\n",
    "      z = np.dot(w.T,X_test[i]) + b\n",
    "      sig = sigmoid(z)\n",
    "      y_test_pred.append(sig)\n",
    "    test_loss.append(logloss(y_test,y_test_pred))  \n",
    "    \n",
    "\n",
    "  return w,b,train_loss , test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "sUquz7LFEZ6E"
   },
   "outputs": [],
   "source": [
    " alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_train)\n",
    "epochs=50\n",
    "w,b,train_loss ,test_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nx8Rs9rfEZ1R",
    "outputId": "2ba9dc49-fb15-4769-c266-2bfe74bd45c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00642552,  0.00755955,  0.00012041, -0.00335043, -0.01309563,\n",
       "          0.00978314,  0.00724319,  0.00418409,  0.0125563 , -0.00701162,\n",
       "          0.00169655, -0.00480346, -0.00173041,  0.00056208,  0.00032075]]),\n",
       " array([-0.03911387]))"
      ]
     },
     "execution_count": 180,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "IeUoCG-o44pU",
    "outputId": "14e0607e-eb9c-4e46-85e8-1509541549af"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = np.arange(50)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure( figsize=(6,5))\n",
    "plt.grid()\n",
    "plt.plot(epoch,train_loss,color='black')\n",
    "plt.plot(epoch,test_loss,color = 'orange')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title('Plot of Epoch Number Vs Train , Test loss',fontsize = 14)\n",
    "plt.legend(['train loss','test loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUN8puFoEZtU",
    "outputId": "d54e3286-f82d-41e5-f1e4-9e0594b87e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9522133333333334\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
