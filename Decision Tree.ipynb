{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e2a67d-6c03-4d3a-9ab7-747a4e80b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance\n",
      "0      Outlook    0.362629\n",
      "3         Wind    0.361204\n",
      "2     Humidity    0.211237\n",
      "1  Temperature    0.064931\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the dataset\n",
    "data = {\n",
    "    'Day': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14'],\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cold', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'Play Tennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = LabelEncoder()\n",
    "df_encoded = df.apply(encoder.fit_transform)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_encoded.drop(columns=['Play Tennis', 'Day'])\n",
    "y = df_encoded['Play Tennis']\n",
    "\n",
    "# Train a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d5feec-a690-4d03-b058-8860887a3862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance\n",
      "0      Outlook    0.482923\n",
      "2     Humidity    0.297163\n",
      "1  Temperature    0.125724\n",
      "3         Wind    0.094191\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the dataset\n",
    "data = {\n",
    "    'Day': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14'],\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cold', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'Play Tennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def entropy(labels):\n",
    "    \"\"\" Calculate the entropy of a list of labels. \"\"\"\n",
    "    prob = labels.value_counts(normalize=True)\n",
    "    return -sum(prob * np.log2(prob))\n",
    "\n",
    "def information_gain(df, feature, target):\n",
    "    \"\"\" Calculate the information gain for a specific feature. \"\"\"\n",
    "    total_entropy = entropy(df[target])\n",
    "    values = df[feature].unique()\n",
    "    weighted_entropy = sum((df[feature] == value).mean() * entropy(df[df[feature] == value][target]) for value in values)\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "# Calculate feature importances\n",
    "target = 'Play Tennis'\n",
    "features = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
    "\n",
    "info_gains = {feature: information_gain(df, feature, target) for feature in features}\n",
    "\n",
    "# Normalize importances to sum to 1\n",
    "total_info_gain = sum(info_gains.values())\n",
    "feature_importances = {feature: info_gains[feature] / total_info_gain for feature in features}\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "feature_importance_df = pd.DataFrame(list(feature_importances.items()), columns=['Feature', 'Importance']).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a8eb844-552e-426b-b1d6-7f3df5ec4cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance\n",
      "0      Outlook         1.0\n",
      "1  Temperature         0.0\n",
      "2     Humidity         0.0\n",
      "3         Wind         0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the dataset\n",
    "data = {\n",
    "    'Day': ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14'],\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cold', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'Play Tennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def entropy(labels):\n",
    "    \"\"\" Calculate the entropy of a list of labels. \"\"\"\n",
    "    prob = labels.value_counts(normalize=True)\n",
    "    return -sum(prob * np.log2(prob))\n",
    "\n",
    "def information_gain(df, feature, target):\n",
    "    \"\"\" Calculate the information gain for a specific feature. \"\"\"\n",
    "    total_entropy = entropy(df[target])\n",
    "    values = df[feature].unique()\n",
    "    weighted_entropy = sum((df[feature] == value).mean() * entropy(df[df[feature] == value][target]) for value in values)\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def build_tree(df, target, features):\n",
    "    \"\"\" Build a decision tree recursively. \"\"\"\n",
    "    # Base case: If all examples have the same label\n",
    "    if len(df[target].unique()) == 1:\n",
    "        return df[target].iloc[0]\n",
    "    \n",
    "    # Base case: If no features are left\n",
    "    if len(features) == 0:\n",
    "        return df[target].mode().iloc[0]\n",
    "    \n",
    "    # Calculate information gain for each feature\n",
    "    gains = {feature: information_gain(df, feature, target) for feature in features}\n",
    "    \n",
    "    # Choose the feature with the highest information gain\n",
    "    best_feature = max(gains, key=gains.get)\n",
    "    \n",
    "    # Recursively build the tree for each value of the best feature\n",
    "    tree = {best_feature: {}}\n",
    "    remaining_features = [f for f in features if f != best_feature]\n",
    "    \n",
    "    for value in df[best_feature].unique():\n",
    "        subtree = build_tree(df[df[best_feature] == value], target, remaining_features)\n",
    "        tree[best_feature][value] = subtree\n",
    "    \n",
    "    return tree\n",
    "\n",
    "def compute_feature_importance(tree, feature_names):\n",
    "    \"\"\" Compute feature importance from a decision tree. \"\"\"\n",
    "    importance = {feature: 0 for feature in feature_names}\n",
    "    \n",
    "    def traverse_tree(node, importance):\n",
    "        if isinstance(node, dict):\n",
    "            feature = list(node.keys())[0]\n",
    "            for value, subnode in node[feature].items():\n",
    "                importance[feature] += traverse_tree(subnode, importance.copy())\n",
    "        return 1\n",
    "    \n",
    "    traverse_tree(tree, importance)\n",
    "    \n",
    "    # Normalize feature importance to sum up to 1\n",
    "    total_importance = sum(importance.values())\n",
    "    normalized_importance = {feature: importance[feature] / total_importance for feature in importance}\n",
    "    \n",
    "    return normalized_importance\n",
    "\n",
    "# Define target and features\n",
    "target = 'Play Tennis'\n",
    "features = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
    "\n",
    "# Build the decision tree\n",
    "tree = build_tree(df, target, features)\n",
    "\n",
    "# Compute feature importance\n",
    "feature_importance = compute_feature_importance(tree, features)\n",
    "\n",
    "# Display feature importance\n",
    "feature_importance_df = pd.DataFrame(list(feature_importance.items()), columns=['Feature', 'Importance']).sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "679993e5-daf1-45d1-b4ba-d508594faf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat importance = [0.08333333 0.25       0.04166667]\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = [[1,0,0], [0,0,0], [0,0,1], [0,1,0]]\n",
    "\n",
    "y = [1,0,1,1]\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "feat_importance = clf.tree_.compute_feature_importances(normalize=False)\n",
    "print(\"feat importance = \" + str(feat_importance))\n",
    "\n",
    "out = StringIO()\n",
    "out = export_graphviz(clf, out_file='tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee3af6-25d3-419c-890e-2c40947119c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
